# Duplicate File Finder Configuration

# Directories to scan (relative to project root or absolute)
scan_directories:
  - downloads
  - documents

# Hash algorithm to use
# Options: md5, sha1, sha256
hash_algorithm: md5

# Minimum file size to check (bytes, 0 = check all files)
min_file_size: 0

# Maximum file size to check (bytes, 0 = no limit)
max_file_size: 0

# Chunk size for reading large files (bytes)
chunk_size: 8192

# Report output file
report_file: data/duplicate_report.json

# Report format
# Options: json, txt, csv
report_format: json

# Exclude patterns (regex)
exclude_patterns:
  - '^\\.'  # Hidden files
  - '\\.tmp$'  # Temporary files
  - '\\.log$'  # Log files

# Exclude directories (regex)
exclude_directories:
  - '^\\.git$'
  - '^\\.venv$'
  - '^__pycache__$'
  - '^node_modules$'

# Recommendations settings
recommendations:
  # Keep the oldest file in each duplicate group
  keep_oldest: true
  
  # Keep the file with shortest path
  keep_shortest_path: false
  
  # Keep files in specific directories (priority order)
  keep_directories:
    - documents
    - important
  
  # Delete recommendations (for report only, not auto-delete)
  suggest_deletion: true

# Logging configuration
logging:
  level: INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  file: logs/duplicate_finder.log
  max_bytes: 10485760  # 10MB
  backup_count: 5
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
