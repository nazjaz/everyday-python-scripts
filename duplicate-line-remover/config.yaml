# Duplicate Line Remover Configuration

# Processing options
processing:
  ignore_case: false  # Ignore case differences when comparing lines
  ignore_whitespace: false  # Ignore whitespace differences (leading/trailing, multiple spaces)
  preserve_empty_lines: true  # Keep empty lines (only remove if duplicate)
  trim_lines: false  # Trim leading/trailing whitespace from lines before comparison
  normalize_whitespace: false  # Normalize multiple spaces to single space

# File handling
file_handling:
  input_encoding: "utf-8"  # Input file encoding
  output_encoding: "utf-8"  # Output file encoding
  backup_original: true  # Create backup of original file before processing
  backup_suffix: ".bak"  # Suffix for backup files
  overwrite_original: false  # Overwrite original file (if false, creates new file with suffix)

# Output settings
output:
  output_suffix: ".deduplicated"  # Suffix for output file if not overwriting
  create_output_file: true  # Create output file
  show_statistics: true  # Show statistics after processing

# Batch processing
batch:
  enabled: false  # Process multiple files
  input_directory: "."  # Directory containing files to process
  file_patterns:  # File patterns to match
    - "*.txt"
    - "*.log"
    - "*.csv"
  recursive: false  # Process subdirectories recursively

# Logging configuration
logging:
  level: INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  file: logs/duplicate_remover.log
  max_bytes: 10485760  # 10MB
  backup_count: 5
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  log_operations: true  # Log all file operations

# Reporting
reporting:
  generate_report: true  # Generate summary report
  report_file: logs/deduplication_report.txt
  include_statistics: true  # Include statistics in report
  include_duplicate_details: false  # Include details of removed duplicates (can be verbose)
